{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import ast\n",
    "import re\n",
    "import math\n",
    "from unicodedata import normalize\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gabarito = pd.read_csv('../gabarito/gabarito.csv')\n",
    "leitura = pd.read_csv('../data/estadao_noticias_eleicao.csv')\n",
    "leitura = leitura.replace(np.nan, '',regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_str(lista):\n",
    "    return ast.literal_eval(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gabarito.google = gabarito.google.apply(convert_str)\n",
    "gabarito.busca_binaria = gabarito.busca_binaria.apply(convert_str)\n",
    "gabarito.tf = gabarito.tf.apply(convert_str)\n",
    "gabarito.tfidf = gabarito.tfidf.apply(convert_str)\n",
    "gabarito.bm25 = gabarito.bm25.apply(convert_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método de limpar frase\n",
    "Método resposavel por limpar o texto e tornar mais eficiente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clear(text):\n",
    "    pattern = re.compile('[^a-zA-Z0-9 ]')\n",
    "    text = normalize('NFKD', text).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    return pattern.sub(' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conteudos = leitura.titulo + \" \" + leitura.subTitulo +  \" \" + leitura.conteudo\n",
    "conteudos  = conteudos .apply(lambda text: \"\" if isinstance(text, float) else text_clear(text).lower())\n",
    "ids = leitura.idNoticia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenização do conteudo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "noticias = conteudos.apply(nltk.word_tokenize)\n",
    "freq_term = noticias.apply(Counter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idexação dos termos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = {}\n",
    "for i in range(len(noticias)):\n",
    "    id_noticia = ids[i]\n",
    "    for palavra in noticias[i]:\n",
    "        palavra = palavra.lower()\n",
    "        if palavra not in index:\n",
    "            index[palavra] = {}\n",
    "        id_rec = index[palavra].get(id_noticia)\n",
    "        \n",
    "        if not id_rec:\n",
    "            docs = index[palavra]\n",
    "            docs[id_noticia] = freq_term[i][palavra]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodo que gera os um dicionario com os pesos dos index-terms\n",
    "Método auxiliar que gera um novo discionario com o index e os pesos associados. Util para analise binaria ou TF. ß"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generador_docs_peso(frase, gerador_peso):\n",
    "    termos = frase.split(\" \")\n",
    "    docs_peso = {}\n",
    "    \n",
    "    for i in range(len(termos)):\n",
    "        termo = termos[i]\n",
    "        docs = index[termo]\n",
    "        for doc_id in docs:\n",
    "            tf = docs[doc_id]\n",
    "            \n",
    "            if doc_id not in docs_peso:\n",
    "                docs_peso[doc_id] = np.array([0 if j != i else gerador_peso(tf) for j in range(len(termos))])\n",
    "            else:\n",
    "                doc_vector = docs_peso[doc_id]\n",
    "                docs_peso[doc_id] = np.array([doc_vector[j] if j != i else gerador_peso(tf) for j in range(len(termos))])\n",
    "    \n",
    "    return docs_peso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método que gera um vetor com tf dos index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_tf(phase):\n",
    "    term = phase.split(' ')\n",
    "    doc_tf = {}\n",
    "    \n",
    "    for i in range(len(term)):\n",
    "        docs = index[term[i]]\n",
    "        for doc_id in docs:\n",
    "            tf = docs[doc_id]\n",
    "            \n",
    "            if doc_id not in doc_tf:\n",
    "                doc_tf[doc_id] = np.array([0 if j != i else tf for j in range(len(term))])\n",
    "            else:\n",
    "                doc_vector = doc_tf[doc_id]\n",
    "                doc_tf[doc_id] = np.array([doc_vector[j] if j != i else tf for j in range(len(term))])\n",
    "    return doc_tf\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método que gera um vetor com valor binario dos index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_binario(frase):\n",
    "    def generador_peso(tf):\n",
    "        return 1\n",
    "    return generador_docs_peso(frase, generador_peso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método que gera um vetor com idf dos index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_idf(phase):\n",
    "    terms = phase.split(' ')\n",
    "    idf  = np.array([math.log((len(noticias)+1)/len(index[term])) for term in terms])\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método que gera um vetor binário de consulta. \n",
    "Considerando os 0 ou 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_query(phase):\n",
    "    terms = phase.split(' ')\n",
    "    query = np.array([1 if index.get(term) else 0 for term in terms])\n",
    "    return query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método que gera um vetor com o bm25 dos termos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generato_bm25(phase):\n",
    "    docs_tf = generator_tf(phase)\n",
    "    k = 5\n",
    "    bm25_vetor = {doc_id: np.array([((k+1)*tf)/(tf+k) for tf in tf_vetor]) for doc_id, tf_vetor in docs_tf.items()}\n",
    "    return bm25_vetor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busca pelo index binario dos termos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seach_bin(phase):\n",
    "    docs_tf = generator_binario(phase)\n",
    "    query = generator_query(phase)\n",
    "    doc_rank = sorted(list(docs_tf.items()), key=lambda doc: np.dot(doc[1], query), reverse=True)[:5] \n",
    "    return [doc[0] for doc in doc_rank]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busca pelo tf dos termos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seach_tf(phase):\n",
    "    docs_tf = generator_tf(phase)\n",
    "    query = generator_query(phase)\n",
    "    doc_rank = sorted(list(docs_tf.items()), key=lambda doc: np.dot(doc[1], query), reverse=True)[:5] \n",
    "    return [doc[0] for doc in doc_rank]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busca pelo tf e idf dos termos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seach_tf_idf(phase):\n",
    "    doc_tf = generator_tf(phase)\n",
    "    doc_idf = generator_idf(phase)\n",
    "    doc_rank = sorted(list(doc_tf.items()), key=lambda doc: np.dot(doc[1], doc_idf), reverse=True)[:5]\n",
    "    return [doc[0] for doc in doc_rank]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busca pelo BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seach_bm25(phase):\n",
    "    doc_bm25 = generato_bm25(phase)\n",
    "    query = generator_query(phase)\n",
    "    doc_rank = sorted(list(doc_bm25.items()), key=lambda doc: np.dot(doc[1], query), reverse=True)[:5]\n",
    "    return [doc[0] for doc in doc_rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes de analise de presição"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste pela busca com o metodo TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local: 0.6520\n",
      "Google:0.0480\n"
     ]
    }
   ],
   "source": [
    "busca_tf = [seach_tf(text_clear(frase)) for frase in gabarito.str_busca]\n",
    "\n",
    "print(\"Local: %.4f\" %(mapk(gabarito.tf, busca_tf, k=5)))\n",
    "print(\"Google:%.4f\" %(mapk(gabarito.google, busca_tf, k=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste pela busca com o metodo binario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local: 0.2400\n",
      "Google:0.0400\n"
     ]
    }
   ],
   "source": [
    "busca_bi  = [seach_bin(text_clear(frase)) for frase in gabarito.str_busca]\n",
    "print(\"Local: %.4f\" %(mapk(gabarito.busca_binaria, busca_bi, k=5)))\n",
    "print(\"Google:%.4f\" %(mapk(gabarito.google, busca_bi, k=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste pela busca com o metodo TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local: 0.6160\n",
      "Google:0.0580\n"
     ]
    }
   ],
   "source": [
    "busca_tf_idf  = [seach_tf_idf(text_clear(frase)) for frase in gabarito.str_busca]\n",
    "print(\"Local: %.4f\" %(mapk(gabarito.tfidf, busca_tf_idf, k=5)))\n",
    "print(\"Google:%.4f\" %(mapk(gabarito.google, busca_tf_idf, k=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste pela busca com o metodo BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local: 0.6787\n",
      "Google:0.1180\n"
     ]
    }
   ],
   "source": [
    "busca_bm25  = [seach_bm25(text_clear(frase)) for frase in gabarito.str_busca]\n",
    "print(\"Local: %.4f\" %(mapk(gabarito.bm25, busca_bm25 , k=5)))\n",
    "print(\"Google:%.4f\" %(mapk(gabarito.google, busca_bm25 , k=5)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
